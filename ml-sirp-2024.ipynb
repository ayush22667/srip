{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.013115,"end_time":"2024-02-24T15:00:13.137080","exception":false,"start_time":"2024-02-24T15:00:13.123965","status":"completed"},"tags":[]},"source":["Used for Folder Structure\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:13.165736Z","iopub.status.busy":"2024-02-24T15:00:13.165466Z","iopub.status.idle":"2024-02-24T15:00:13.175459Z","shell.execute_reply":"2024-02-24T15:00:13.174770Z"},"papermill":{"duration":0.025915,"end_time":"2024-02-24T15:00:13.177269","exception":false,"start_time":"2024-02-24T15:00:13.151354","status":"completed"},"tags":[]},"outputs":[],"source":["import os \n","from PIL import Image\n","import shutil\n","import random"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.013184,"end_time":"2024-02-24T15:00:13.203833","exception":false,"start_time":"2024-02-24T15:00:13.190649","status":"completed"},"tags":[]},"source":["Used for DL and Visualisation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:13.231595Z","iopub.status.busy":"2024-02-24T15:00:13.231339Z","iopub.status.idle":"2024-02-24T15:00:21.455572Z","shell.execute_reply":"2024-02-24T15:00:21.454763Z"},"papermill":{"duration":8.240679,"end_time":"2024-02-24T15:00:21.457898","exception":false,"start_time":"2024-02-24T15:00:13.217219","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","\n","import torchvision\n","from torchvision import transforms\n","\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.013325,"end_time":"2024-02-24T15:00:21.485108","exception":false,"start_time":"2024-02-24T15:00:21.471783","status":"completed"},"tags":[]},"source":["# Folder Structure"]},{"cell_type":"markdown","metadata":{},"source":["Study of Image type and folder structure for further analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:21.515137Z","iopub.status.busy":"2024-02-24T15:00:21.514698Z","iopub.status.idle":"2024-02-24T15:00:21.518837Z","shell.execute_reply":"2024-02-24T15:00:21.518116Z"},"papermill":{"duration":0.021066,"end_time":"2024-02-24T15:00:21.520772","exception":false,"start_time":"2024-02-24T15:00:21.499706","status":"completed"},"tags":[]},"outputs":[],"source":["# The folder is contained in this directory\n","animal_dir = \"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:21.549587Z","iopub.status.busy":"2024-02-24T15:00:21.549156Z","iopub.status.idle":"2024-02-24T15:00:21.594974Z","shell.execute_reply":"2024-02-24T15:00:21.594104Z"},"papermill":{"duration":0.062547,"end_time":"2024-02-24T15:00:21.596924","exception":false,"start_time":"2024-02-24T15:00:21.534377","status":"completed"},"tags":[]},"outputs":[],"source":["\n","len(os.listdir(animal_dir))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-24T15:00:21.625145Z","iopub.status.busy":"2024-02-24T15:00:21.624864Z","iopub.status.idle":"2024-02-24T15:00:21.631517Z","shell.execute_reply":"2024-02-24T15:00:21.630669Z"},"papermill":{"duration":0.022799,"end_time":"2024-02-24T15:00:21.633421","exception":false,"start_time":"2024-02-24T15:00:21.610622","status":"completed"},"tags":[]},"outputs":[],"source":["with open(\"/kaggle/input/animal-image-dataset-90-different-animals/name of the animals.txt\", 'r') as f:\n","    animal_info = f.read()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:21.661783Z","iopub.status.busy":"2024-02-24T15:00:21.661509Z","iopub.status.idle":"2024-02-24T15:00:21.665768Z","shell.execute_reply":"2024-02-24T15:00:21.664863Z"},"papermill":{"duration":0.021101,"end_time":"2024-02-24T15:00:21.668129","exception":false,"start_time":"2024-02-24T15:00:21.647028","status":"completed"},"tags":[]},"outputs":[],"source":["print(animal_info.split())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:21.696284Z","iopub.status.busy":"2024-02-24T15:00:21.695990Z","iopub.status.idle":"2024-02-24T15:00:21.701096Z","shell.execute_reply":"2024-02-24T15:00:21.700275Z"},"papermill":{"duration":0.021446,"end_time":"2024-02-24T15:00:21.703023","exception":false,"start_time":"2024-02-24T15:00:21.681577","status":"completed"},"tags":[]},"outputs":[],"source":["len(animal_info.split())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T13:29:39.136628Z","iopub.status.busy":"2024-02-24T13:29:39.136349Z","iopub.status.idle":"2024-02-24T13:29:39.140556Z","shell.execute_reply":"2024-02-24T13:29:39.139664Z","shell.execute_reply.started":"2024-02-24T13:29:39.136605Z"},"papermill":{"duration":0.013722,"end_time":"2024-02-24T15:00:21.730558","exception":false,"start_time":"2024-02-24T15:00:21.716836","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:21.759096Z","iopub.status.busy":"2024-02-24T15:00:21.758856Z","iopub.status.idle":"2024-02-24T15:00:22.798789Z","shell.execute_reply":"2024-02-24T15:00:22.797776Z"},"papermill":{"duration":1.056845,"end_time":"2024-02-24T15:00:22.801154","exception":false,"start_time":"2024-02-24T15:00:21.744309","status":"completed"},"tags":[]},"outputs":[],"source":["\n","animal_names = {} \n","animal_directories = os.listdir(animal_dir)\n","\n","for animal_name in animal_directories:\n","    animal_path = os.path.join(animal_dir, animal_name)\n","    num_images = len(os.listdir(animal_path))\n","    animal_names[animal_name] = num_images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:22.831163Z","iopub.status.busy":"2024-02-24T15:00:22.830878Z","iopub.status.idle":"2024-02-24T15:00:22.839482Z","shell.execute_reply":"2024-02-24T15:00:22.838595Z"},"papermill":{"duration":0.025378,"end_time":"2024-02-24T15:00:22.841479","exception":false,"start_time":"2024-02-24T15:00:22.816101","status":"completed"},"tags":[]},"outputs":[],"source":["animal_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T13:29:40.798229Z","iopub.status.busy":"2024-02-24T13:29:40.797856Z","iopub.status.idle":"2024-02-24T13:29:40.803419Z","shell.execute_reply":"2024-02-24T13:29:40.802502Z","shell.execute_reply.started":"2024-02-24T13:29:40.798198Z"},"papermill":{"duration":0.013774,"end_time":"2024-02-24T15:00:22.869324","exception":false,"start_time":"2024-02-24T15:00:22.855550","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:22.898592Z","iopub.status.busy":"2024-02-24T15:00:22.898312Z","iopub.status.idle":"2024-02-24T15:00:22.913338Z","shell.execute_reply":"2024-02-24T15:00:22.912425Z"},"papermill":{"duration":0.031733,"end_time":"2024-02-24T15:00:22.915207","exception":false,"start_time":"2024-02-24T15:00:22.883474","status":"completed"},"tags":[]},"outputs":[],"source":["\n","image_path = \"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals/antelope/02f4b3be2d.jpg\"\n","image = Image.open(image_path)\n","width, height = image.size\n","print(f\"width: {width}, height: {height}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.013935,"end_time":"2024-02-24T15:00:22.943478","exception":false,"start_time":"2024-02-24T15:00:22.929543","status":"completed"},"tags":[]},"source":["# **One vs Rest Classification**"]},{"cell_type":"markdown","metadata":{},"source":["This dataset class retrieves all images from the folder at the `ith` index, as well as `10%` of the images from each of the other folders. This approach helps to conserve memory and end potential train and test problems arising from significant discrepancies in image numbers across folders.\n","\n","\n","```\n","Note: Earlier the dataset took `ith` folder (60) images, and (5340) images in the rest folder, but this caused errors so, in the final version of the code this issue was solved using this method.\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:22.972815Z","iopub.status.busy":"2024-02-24T15:00:22.972131Z","iopub.status.idle":"2024-02-24T15:00:22.976062Z","shell.execute_reply":"2024-02-24T15:00:22.975215Z"},"papermill":{"duration":0.020349,"end_time":"2024-02-24T15:00:22.977905","exception":false,"start_time":"2024-02-24T15:00:22.957556","status":"completed"},"tags":[]},"outputs":[],"source":["path = \"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\""]},{"cell_type":"markdown","metadata":{},"source":["In the transform, the mean is ```mean=[0.485, 0.456, 0.406]``` and ```std=[0.229, 0.224, 0.225]``` to normalize images because it is given by PyTorch by default and is the Imagenet default values and in practice it is assumed to work better then rest values."]},{"cell_type":"markdown","metadata":{},"source":["The label is 0 and 1."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:23.007061Z","iopub.status.busy":"2024-02-24T15:00:23.006793Z","iopub.status.idle":"2024-02-24T15:00:23.017338Z","shell.execute_reply":"2024-02-24T15:00:23.016469Z"},"papermill":{"duration":0.027024,"end_time":"2024-02-24T15:00:23.019119","exception":false,"start_time":"2024-02-24T15:00:22.992095","status":"completed"},"tags":[]},"outputs":[],"source":["class dataset_new(torch.utils.data.Dataset):\n","    def __init__(self,data_idx,take=0.1,path=path):\n","        super().__init__()\n","        classes = os.listdir(path)\n","        folder_name = classes[data_idx]\n","        self.images = []\n","        self.labels = []\n","        self.transforms = transforms.Compose([\n","            transforms.Resize(256), # 256 for efficient net , 224\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","            ])\n","        for folder in classes:\n","            if folder==folder_name:\n","                limit = 1\n","            else:\n","                limit = take\n","            anim_fold = os.path.join(path, folder)\n","            for l,localpath in enumerate(os.listdir(anim_fold)):\n","                if(l>=limit*len(os.listdir(anim_fold))):\n","                    break\n","                img_path = os.path.join(anim_fold, localpath)\n","                self.images.append(img_path)\n","                if folder==folder_name:\n","                    self.labels.append(1)\n","                else:\n","                    self.labels.append(0)\n","        \n","    def __len__(self):\n","        return len(self.images)\n","    def __getitem__(self,idx):\n","        img = Image.open(self.images[idx])\n","        label = self.labels[idx]\n","        return self.transforms(img), torch.tensor(label,dtype=torch.long)\n","      "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T13:29:50.858502Z","iopub.status.busy":"2024-02-24T13:29:50.858254Z","iopub.status.idle":"2024-02-24T13:29:50.870477Z","shell.execute_reply":"2024-02-24T13:29:50.869571Z","shell.execute_reply.started":"2024-02-24T13:29:50.858480Z"},"papermill":{"duration":0.013755,"end_time":"2024-02-24T15:00:23.046754","exception":false,"start_time":"2024-02-24T15:00:23.032999","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.052106,"end_time":"2024-02-24T15:00:23.113059","exception":false,"start_time":"2024-02-24T15:00:23.060953","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["```run_label_classification_one_vs_rest_fold```, this function is the main structure, and works to run the model using different models and perform calcualtions. It does 3fold CV with 3 epochs each using one_vs_rest and displays the test and train, accuracy and loss value after each epoch and also saves the plot."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:23.142937Z","iopub.status.busy":"2024-02-24T15:00:23.142370Z","iopub.status.idle":"2024-02-24T15:00:23.162155Z","shell.execute_reply":"2024-02-24T15:00:23.161293Z"},"papermill":{"duration":0.036922,"end_time":"2024-02-24T15:00:23.164032","exception":false,"start_time":"2024-02-24T15:00:23.127110","status":"completed"},"tags":[]},"outputs":[],"source":["def run_label_classification_one_vs_rest_fold(model_net, name):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    name_model = str(name)\n","    for i in range(90):\n","        print(animal_info.split()[i])\n","        dataset = dataset_new(i)\n","\n","        kfold = KFold(n_splits=3, shuffle=True)\n","\n","        print('--------------------------------')\n","\n","        for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n","\n","            print(f'FOLD {fold}')\n","            print('--------------------------------')\n","\n","            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","\n","            train_loader = DataLoader(dataset, batch_size=32, sampler=train_subsampler, pin_memory=True, num_workers=2)\n","            test_loader = DataLoader(dataset, batch_size=32, sampler=test_subsampler, pin_memory=True, num_workers=2)\n","\n","            model = model_net\n","            model.to(device)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=5e-5)\n","            train_losses = []\n","            test_losses = []\n","            train_accuracies = []\n","            test_accuracies = []\n","\n","            for epoch in range(3):\n","\n","                model.train()\n","                correct = 0\n","                total = 0\n","                train_loss = 0.0\n","                for _, (inputs, labels) in enumerate(train_loader):\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","                    optimizer.zero_grad()\n","\n","                    outputs = model(inputs)\n","                    loss = nn.CrossEntropyLoss()(outputs, labels)\n","                    loss.backward()\n","                    optimizer.step()\n","                    train_loss += loss.item()\n","                    _, predicted = outputs.max(1)\n","                    total += labels.size(0)\n","                    correct += predicted.eq(labels).sum().item()\n","\n","                model.eval()  \n","                test_loss = 0.0\n","                test_correct = 0\n","                test_total = 0\n","                all_labels = []\n","                all_predictions = []\n","\n","                for inputs, labels in test_loader:\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","                    outputs = model(inputs)\n","                    loss = nn.CrossEntropyLoss()(outputs, labels)\n","                    test_loss += loss.item()*inputs.size(0)\n","                    _, predicted = outputs.max(1)\n","                    test_total += labels.size(0)\n","                    test_correct += predicted.eq(labels).sum().item()\n","                    all_labels.extend(labels.cpu().numpy())\n","                    all_predictions.extend(predicted.cpu().numpy())\n","\n","\n","                test_loss = test_loss / len(test_loader)\n","                train_loss = train_loss/len(train_loader)\n","                test_accuracy = 100.0 * correct / total\n","                train_accuracy = 100.0 * test_correct/test_total\n","\n","                train_losses.append(train_loss)\n","                test_losses.append(test_loss)\n","                train_accuracies.append(train_accuracy)\n","                test_accuracies.append(test_accuracy)\n","\n","                print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f} \\tTrain Accuracy {:.6f}% \\tTest Accuracy: {:.2f}%'.format(\n","                    epoch+1, \n","                    train_loss,\n","                    test_loss,\n","                    train_accuracy,\n","                    test_accuracy\n","                    ))\n","                \n","            directory = f'/kaggle/working/one-vs-rest/{name}/{animal_info.split()[i]}/'\n","            os.makedirs(directory, exist_ok=True)\n","\n","            plt.figure(figsize=(10, 5))\n","            plt.plot(train_accuracies, label='Train Accuracy')\n","            plt.plot(test_accuracies, label='Test Accuracy')\n","            plt.title('Accuracy Curve for Dataset Name: {} Fold {}'.format(animal_info.split()[i], fold))\n","            plt.xlabel('Epoch')\n","            plt.ylabel('Accuracy')\n","            plt.savefig(os.path.join(directory, f'{fold}.png'))\n","\n","\n","            print('Confusion Matrix for fold {}'.format(fold))\n","            print(confusion_matrix(all_labels, all_predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.013818,"end_time":"2024-02-24T15:00:23.191918","exception":false,"start_time":"2024-02-24T15:00:23.178100","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.013882,"end_time":"2024-02-24T15:00:23.219800","exception":false,"start_time":"2024-02-24T15:00:23.205918","status":"completed"},"tags":[]},"source":["Model using Efficientnet b0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:23.249352Z","iopub.status.busy":"2024-02-24T15:00:23.249031Z","iopub.status.idle":"2024-02-24T15:00:38.958031Z","shell.execute_reply":"2024-02-24T15:00:38.956937Z"},"papermill":{"duration":15.726313,"end_time":"2024-02-24T15:00:38.960371","exception":false,"start_time":"2024-02-24T15:00:23.234058","status":"completed"},"tags":[]},"outputs":[],"source":["!pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:15:02.244092Z","iopub.status.busy":"2024-02-23T17:15:02.243702Z","iopub.status.idle":"2024-02-23T17:15:02.257983Z","shell.execute_reply":"2024-02-23T17:15:02.257053Z","shell.execute_reply.started":"2024-02-23T17:15:02.244053Z"},"papermill":{"duration":0.014603,"end_time":"2024-02-24T15:00:38.990152","exception":false,"start_time":"2024-02-24T15:00:38.975549","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T15:00:39.021550Z","iopub.status.busy":"2024-02-24T15:00:39.020909Z","iopub.status.idle":"2024-02-24T16:11:31.289258Z","shell.execute_reply":"2024-02-24T16:11:31.288137Z"},"papermill":{"duration":4252.28673,"end_time":"2024-02-24T16:11:31.291518","exception":false,"start_time":"2024-02-24T15:00:39.004788","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["\n","from efficientnet_pytorch import EfficientNet\n","\n","class CEfficientNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n","        self.fc = nn.Linear(1000, 2)\n","\n","    def forward(self, x):\n","        x = self.efficientnet(x)\n","        x = self.fc(x)\n","        return x\n","\n","model_EfficientNet = CEfficientNet()\n","run_label_classification_one_vs_rest_fold(model_EfficientNet, 'Effnet')"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.25485,"end_time":"2024-02-24T16:11:31.811724","exception":false,"start_time":"2024-02-24T16:11:31.556874","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.23828,"end_time":"2024-02-24T16:11:32.288007","exception":false,"start_time":"2024-02-24T16:11:32.049727","status":"completed"},"tags":[]},"source":["Model using MobileNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T16:11:32.775712Z","iopub.status.busy":"2024-02-24T16:11:32.775316Z","iopub.status.idle":"2024-02-24T17:21:48.144685Z","shell.execute_reply":"2024-02-24T17:21:48.143659Z"},"papermill":{"duration":4215.614493,"end_time":"2024-02-24T17:21:48.147027","exception":false,"start_time":"2024-02-24T16:11:32.532534","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["\n","from torchvision import models\n","\n","class CMobileNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.mobilenet = models.mobilenet_v2(pretrained=True)\n","        self.fc = nn.Linear(1000, 2)\n","\n","    def forward(self, x):\n","        x = self.mobilenet(x)\n","        x = self.fc(x)\n","        return x\n","    \n","model_MobileNet = CMobileNet()\n","run_label_classification_one_vs_rest_fold(model_MobileNet, 'Mobilenet')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.498804,"end_time":"2024-02-24T17:21:49.166283","exception":false,"start_time":"2024-02-24T17:21:48.667479","status":"completed"},"tags":[]},"source":["Model using CustomNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T17:21:50.157137Z","iopub.status.busy":"2024-02-24T17:21:50.156744Z","iopub.status.idle":"2024-02-24T18:33:10.394755Z","shell.execute_reply":"2024-02-24T18:33:10.393687Z"},"papermill":{"duration":4280.732885,"end_time":"2024-02-24T18:33:10.397104","exception":false,"start_time":"2024-02-24T17:21:49.664219","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["\n","class Attention(nn.Module):\n","    def __init__(self, in_features):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","            nn.Linear(in_features, in_features),\n","            nn.Tanh(),\n","            nn.Linear(in_features, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        attention_weights = self.attention(x)\n","        return attention_weights * x\n","\n","class CustomCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(64*56*56, 1000) \n","        self.attention = Attention(1000)\n","        self.fc2 = nn.Linear(1000, 2)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = x.view(x.size(0), -1) \n","        x = F.relu(self.fc1(x))\n","        x = self.attention(x)\n","        x = self.fc2(x)\n","        return x\n","\n","model_CustomCNN = CustomCNN()\n","run_label_classification_one_vs_rest_fold(model_CustomCNN, 'CustomCNN')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.859197,"end_time":"2024-02-24T18:33:12.028488","exception":false,"start_time":"2024-02-24T18:33:11.169291","status":"completed"},"tags":[]},"source":["# 5 Class Classification using 3 Fold CV"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:33:13.571201Z","iopub.status.busy":"2024-02-24T18:33:13.570155Z","iopub.status.idle":"2024-02-24T18:33:13.575041Z","shell.execute_reply":"2024-02-24T18:33:13.574161Z"},"papermill":{"duration":0.776609,"end_time":"2024-02-24T18:33:13.576846","exception":false,"start_time":"2024-02-24T18:33:12.800237","status":"completed"},"tags":[]},"outputs":[],"source":["path = \"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:33:15.136235Z","iopub.status.busy":"2024-02-24T18:33:15.135314Z","iopub.status.idle":"2024-02-24T18:33:15.146070Z","shell.execute_reply":"2024-02-24T18:33:15.145278Z"},"papermill":{"duration":0.794446,"end_time":"2024-02-24T18:33:15.148068","exception":false,"start_time":"2024-02-24T18:33:14.353622","status":"completed"},"tags":[]},"outputs":[],"source":["class dataset_pent_class(torch.utils.data.Dataset):\n","    def __init__(self,start_idx, path=path, window_size= 5):\n","        super().__init__()\n","        classes = os.listdir(path)\n","        self.images = []\n","        self.labels = []\n","        self.transforms = transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","            ])\n","        end_idx = start_idx*5 + window_size\n","        for i in range(start_idx*5, end_idx):\n","            folder_name = classes[i] \n","            anim_fold = os.path.join(path, folder_name)\n","            for localpath in os.listdir(anim_fold):\n","                img_path = os.path.join(anim_fold, localpath)\n","                self.images.append(img_path)\n","                self.labels.append(i % window_size)  \n","        \n","    def __len__(self):\n","        return len(self.images)\n","    def __getitem__(self,idx):\n","        img = Image.open(self.images[idx])\n","        label = self.labels[idx]\n","        return self.transforms(img), torch.tensor(label, dtype=torch.long)\n","      "]},{"cell_type":"markdown","metadata":{},"source":["```run_label_classification_one_vs_rest_fold``` even though the method name is the same, this takes multiple inputs, and saves the model weights. These weights are then loaded to visualise the model view images after the full process."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:33:16.811875Z","iopub.status.busy":"2024-02-24T18:33:16.811474Z","iopub.status.idle":"2024-02-24T18:33:16.838412Z","shell.execute_reply":"2024-02-24T18:33:16.837448Z"},"papermill":{"duration":0.915254,"end_time":"2024-02-24T18:33:16.840424","exception":false,"start_time":"2024-02-24T18:33:15.925170","status":"completed"},"tags":[]},"outputs":[],"source":["def run_label_classification_one_vs_rest_fold(model_net, name, start_idx=0, window_size=5):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    name_model = str(name)\n","    for i in range(start_idx, 17, window_size):\n","        print(i, \"structure folder\")\n","        dataset = dataset_pent_class(i, window_size=window_size)\n","\n","        kfold = KFold(n_splits=3, shuffle=True)\n","\n","        print('--------------------------------')\n","\n","        for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n","\n","            print(f'FOLD {fold}')\n","            print('--------------------------------')\n","\n","            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","\n","            train_loader = DataLoader(dataset, batch_size=32, sampler=train_subsampler, pin_memory=True, num_workers=2)\n","            test_loader = DataLoader(dataset, batch_size=32, sampler=test_subsampler, pin_memory=True, num_workers=2)\n","\n","            model = model_net\n","            model.to(device)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=5e-5)\n","            train_losses = []\n","            test_losses = []\n","            train_accuracies = []\n","            test_accuracies = []\n","\n","            for epoch in range(3):\n","\n","                model.train()\n","                correct = 0\n","                total = 0\n","                train_loss = 0.0\n","                for _, (inputs, labels) in enumerate(train_loader):\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","                    optimizer.zero_grad()\n","\n","                    outputs = model(inputs)\n","                    loss = nn.CrossEntropyLoss()(outputs, labels)\n","                    loss.backward()\n","                    optimizer.step()\n","                    train_loss += loss.item()\n","                    _, predicted = outputs.max(1)\n","                    total += labels.size(0)\n","                    correct += predicted.eq(labels).sum().item()\n","\n","                model.eval()  \n","                test_loss = 0.0\n","                test_correct = 0\n","                test_total = 0\n","                all_labels = []\n","                all_predictions = []\n","\n","                for inputs, labels in test_loader:\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","                    outputs = model(inputs)\n","                    loss = nn.CrossEntropyLoss()(outputs, labels)\n","                    test_loss += loss.item()*inputs.size(0)\n","                    _, predicted = outputs.max(1)\n","                    test_total += labels.size(0)\n","                    test_correct += predicted.eq(labels).sum().item()\n","                    all_labels.extend(labels.cpu().numpy())\n","                    all_predictions.extend(predicted.cpu().numpy())\n","\n","\n","                test_loss = test_loss / len(test_loader)\n","                train_loss = train_loss/len(train_loader)\n","                test_accuracy = 100.0 * correct / total\n","                train_accuracy = 100.0 * test_correct/test_total\n","\n","                train_losses.append(train_loss)\n","                test_losses.append(test_loss)\n","                train_accuracies.append(train_accuracy)\n","                test_accuracies.append(test_accuracy)\n","\n","                print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f} \\tTrain Accuracy {:.6f}% \\tTest Accuracy: {:.2f}%'.format(\n","                    epoch+1, \n","                    train_loss,\n","                    test_loss,\n","                    train_accuracy,\n","                    test_accuracy\n","                    ))\n","                \n","            directory = f'/kaggle/working/5fold/{i}/{fold}/'\n","            os.makedirs(directory, exist_ok=True)\n","\n","            plt.figure(figsize=(10, 5))\n","            plt.plot(train_accuracies, label='Train Accuracy')\n","            plt.plot(test_accuracies, label='Test Accuracy')\n","            plt.title('Accuracy Curve for {} Dataset, Fold {}'.format(i, fold))\n","            plt.xlabel('Epoch')\n","            plt.ylabel('Accuracy')\n","            plt.savefig(os.path.join(directory, f'{fold}.png'))\n","            \n","            model_directory = f'/kaggle/working/5fold_model/'\n","            os.makedirs(model_directory, exist_ok=True)\n","            torch.save(model.state_dict(), os.path.join(model_directory, f'{name_model}.pth'))\n","\n","\n","            print('Confusion Matrix for fold {}'.format(fold))\n","            print(confusion_matrix(all_labels, all_predictions))\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.757349,"end_time":"2024-02-24T18:33:18.370206","exception":false,"start_time":"2024-02-24T18:33:17.612857","status":"completed"},"tags":[]},"source":["EfficientNet b0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:33:19.983068Z","iopub.status.busy":"2024-02-24T18:33:19.982654Z","iopub.status.idle":"2024-02-24T18:33:32.093947Z","shell.execute_reply":"2024-02-24T18:33:32.092727Z"},"papermill":{"duration":12.875395,"end_time":"2024-02-24T18:33:32.096371","exception":false,"start_time":"2024-02-24T18:33:19.220976","status":"completed"},"tags":[]},"outputs":[],"source":["!pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:33:33.626630Z","iopub.status.busy":"2024-02-24T18:33:33.626214Z","iopub.status.idle":"2024-02-24T18:35:30.924466Z","shell.execute_reply":"2024-02-24T18:35:30.923318Z"},"papermill":{"duration":118.068024,"end_time":"2024-02-24T18:35:30.926707","exception":false,"start_time":"2024-02-24T18:33:32.858683","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["\n","from efficientnet_pytorch import EfficientNet\n","\n","class CEfficientNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n","        self.fc = nn.Linear(1000, 5)\n","\n","    def forward(self, x):\n","        x = self.efficientnet(x)\n","        x = self.fc(x)\n","        return x\n","\n","model_EfficientNet = CEfficientNet()\n","run_label_classification_one_vs_rest_fold(model_EfficientNet, 'EffNet', 0, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.777862,"end_time":"2024-02-24T18:35:32.481602","exception":false,"start_time":"2024-02-24T18:35:31.703740","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.773077,"end_time":"2024-02-24T18:35:34.100053","exception":false,"start_time":"2024-02-24T18:35:33.326976","status":"completed"},"tags":[]},"source":["MobileNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:35:35.742612Z","iopub.status.busy":"2024-02-24T18:35:35.742193Z","iopub.status.idle":"2024-02-24T18:37:26.105036Z","shell.execute_reply":"2024-02-24T18:37:26.104065Z"},"papermill":{"duration":111.181573,"end_time":"2024-02-24T18:37:26.107190","exception":false,"start_time":"2024-02-24T18:35:34.925617","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["\n","from torchvision import models\n","\n","class CMobileNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.mobilenet = models.mobilenet_v2(pretrained=True)\n","        self.fc = nn.Linear(1000, 5)\n","\n","    def forward(self, x):\n","        x = self.mobilenet(x)\n","        x = self.fc(x)\n","        return x\n","    \n","model_MobileNet = CMobileNet()\n","run_label_classification_one_vs_rest_fold(model_MobileNet, 'MobileNet', 0, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.778811,"end_time":"2024-02-24T18:37:27.667799","exception":false,"start_time":"2024-02-24T18:37:26.888988","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.988864,"end_time":"2024-02-24T18:37:29.441032","exception":false,"start_time":"2024-02-24T18:37:28.452168","status":"completed"},"tags":[]},"source":["Custom NeuralNetwork"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:37:30.999044Z","iopub.status.busy":"2024-02-24T18:37:30.998137Z","iopub.status.idle":"2024-02-24T18:39:48.267146Z","shell.execute_reply":"2024-02-24T18:39:48.266107Z"},"papermill":{"duration":138.050488,"end_time":"2024-02-24T18:39:48.269337","exception":false,"start_time":"2024-02-24T18:37:30.218849","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["\n","\n","class Attention(nn.Module):\n","    def __init__(self, in_features):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","            nn.Linear(in_features, in_features),\n","            nn.Tanh(),\n","            nn.Linear(in_features, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        attention_weights = self.attention(x)\n","        return attention_weights * x\n","    \n","class CustomCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(64*56*56, 1000) \n","        self.attention = Attention(1000)\n","        self.fc2 = nn.Linear(1000, 5) \n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = x.view(x.size(0), -1) \n","        x = F.relu(self.fc1(x))\n","        x = self.attention(x)\n","        x = self.fc2(x)\n","        return x\n","\n","model_CustomCNN = CustomCNN()\n","run_label_classification_one_vs_rest_fold(model_CustomCNN, 'CustomCNN', 0, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.955671,"end_time":"2024-02-24T18:39:50.052944","exception":false,"start_time":"2024-02-24T18:39:49.097273","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.851534,"end_time":"2024-02-24T18:39:51.754653","exception":false,"start_time":"2024-02-24T18:39:50.903119","status":"completed"},"tags":[]},"source":["# Model Visualisation "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:39:53.429566Z","iopub.status.busy":"2024-02-24T18:39:53.429140Z","iopub.status.idle":"2024-02-24T18:39:53.439204Z","shell.execute_reply":"2024-02-24T18:39:53.438303Z"},"papermill":{"duration":0.839727,"end_time":"2024-02-24T18:39:53.441429","exception":false,"start_time":"2024-02-24T18:39:52.601702","status":"completed"},"scrolled":true,"tags":[]},"outputs":[],"source":["import torchvision\n","from torchvision import models, transforms, utils\n","from torch.autograd import Variable\n","import scipy.misc\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:39:55.124032Z","iopub.status.busy":"2024-02-24T18:39:55.122845Z","iopub.status.idle":"2024-02-24T18:39:55.129079Z","shell.execute_reply":"2024-02-24T18:39:55.128194Z"},"papermill":{"duration":0.849538,"end_time":"2024-02-24T18:39:55.131286","exception":false,"start_time":"2024-02-24T18:39:54.281748","status":"completed"},"tags":[]},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.873119,"end_time":"2024-02-24T18:39:56.829031","exception":false,"start_time":"2024-02-24T18:39:55.955912","status":"completed"},"tags":[]},"source":["Using the same transform as used during dataloading"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.927076,"end_time":"2024-02-24T18:39:58.594372","exception":false,"start_time":"2024-02-24T18:39:57.667296","status":"completed"},"tags":[]},"source":["Plotting the output of all convolutional layers and discuss the insights on automatically created features."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:40:00.264311Z","iopub.status.busy":"2024-02-24T18:40:00.263359Z","iopub.status.idle":"2024-02-24T18:40:00.919520Z","shell.execute_reply":"2024-02-24T18:40:00.918530Z"},"papermill":{"duration":1.510591,"end_time":"2024-02-24T18:40:00.924832","exception":false,"start_time":"2024-02-24T18:39:59.414241","status":"completed"},"tags":[]},"outputs":[],"source":["#Taking an Image\n","image = Image.open(str('/kaggle/input/animal-image-dataset-90-different-animals/animals/animals/antelope/02f4b3be2d.jpg'))\n","plt.imshow(image)\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.841725,"end_time":"2024-02-24T18:40:02.603585","exception":false,"start_time":"2024-02-24T18:40:01.761860","status":"completed"},"tags":[]},"source":["# Function for Visual\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:40:04.246177Z","iopub.status.busy":"2024-02-24T18:40:04.245685Z","iopub.status.idle":"2024-02-24T18:40:04.263684Z","shell.execute_reply":"2024-02-24T18:40:04.262739Z"},"papermill":{"duration":0.84196,"end_time":"2024-02-24T18:40:04.265756","exception":false,"start_time":"2024-02-24T18:40:03.423796","status":"completed"},"tags":[]},"outputs":[],"source":["transforms = transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","        ])\n","\n","def nn_layer_visual(image, model, model_path):\n","        \n","        model.load_state_dict(torch.load(model_path))\n","\n","        \n","        model_weights =[]\n","        conv_layers = []\n","        model_children = list(model.children())\n","        counter = 0\n","        for i in range(len(model_children)):\n","            if type(model_children[i]) == nn.Conv2d:\n","                counter+=1\n","                model_weights.append(model_children[i].weight)\n","                conv_layers.append(model_children[i])\n","            elif type(model_children[i]) == nn.Sequential:\n","                for j in range(len(model_children[i])):\n","                    for child in model_children[i][j].children():\n","                        if type(child) == nn.Conv2d:\n","                            counter+=1\n","                            model_weights.append(child.weight)\n","                            conv_layers.append(child)\n","        print(f\"Total convolution layers: {counter}\")\n","        print(\"conv_layers\")\n","\n","        image = transforms(image)\n","        print(f\"Image shape before: {image.shape}\")\n","        image = image.unsqueeze(0)\n","        print(f\"Image shape after: {image.shape}\")\n","\n","        if len(image.shape) == 3:\n","            image = image.unsqueeze(0)\n","\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        image = image.to(device)\n","\n","        print(f\"Image shape before: {image.shape}\")\n","\n","        outputs = []\n","        names = []\n","        for layer in conv_layers[0:]:\n","            image = layer(image)\n","            outputs.append(image)\n","            names.append(str(layer))\n","\n","        print(len(outputs))\n","        for feature_map in outputs:\n","            print(feature_map.shape)\n","\n","        processed = []\n","        for feature_map in outputs:\n","            feature_map = feature_map.squeeze(0)\n","            gray_scale = torch.sum(feature_map,0)\n","            gray_scale = gray_scale / feature_map.shape[0]\n","            processed.append(gray_scale.data.cpu().numpy())\n","        for fm in processed:\n","            print(fm.shape)\n","\n","        fig = plt.figure(figsize=(30, 50))\n","        for i in range(len(processed)):\n","            a = fig.add_subplot(5, 4, i+1)\n","            imgplot = plt.imshow(processed[i])\n","            a.axis(\"off\")\n","            a.set_title(names[i].split('(')[0], fontsize=30)\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.83987,"end_time":"2024-02-24T18:40:05.930562","exception":false,"start_time":"2024-02-24T18:40:05.090692","status":"completed"},"tags":[]},"source":["# Custom CNN Visual"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T18:40:07.639621Z","iopub.status.busy":"2024-02-24T18:40:07.639081Z","iopub.status.idle":"2024-02-24T18:40:09.020143Z","shell.execute_reply":"2024-02-24T18:40:09.019193Z"},"papermill":{"duration":2.196922,"end_time":"2024-02-24T18:40:09.028022","exception":false,"start_time":"2024-02-24T18:40:06.831100","status":"completed"},"tags":[]},"outputs":[],"source":["nn_layer_visual(image, model_CustomCNN, '/kaggle/working/5fold_model/CustomCNN.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.816762,"end_time":"2024-02-24T18:40:10.684487","exception":false,"start_time":"2024-02-24T18:40:09.867725","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.833926,"end_time":"2024-02-24T18:40:12.336741","exception":false,"start_time":"2024-02-24T18:40:11.502815","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.835225,"end_time":"2024-02-24T18:40:14.000055","exception":false,"start_time":"2024-02-24T18:40:13.164830","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1554380,"sourceId":3952946,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":13206.847884,"end_time":"2024-02-24T18:40:17.197320","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-24T15:00:10.349436","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}
